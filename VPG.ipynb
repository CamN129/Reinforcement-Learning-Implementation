{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c8209ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical\n",
    "import numpy as np\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d26b11a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class policynet(nn.Module):\n",
    "    def __init__(self, s, h, a): # s-state space, hidden layer size, action space\n",
    "        super(policynet, self).__init__()\n",
    "        self.hl = nn.Linear(s,h)\n",
    "        self.out = nn.Linear(h,a)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.hl(x))\n",
    "        x = self.out(x)\n",
    "        \n",
    "        #x = F.softmax(self.out(x),dim=1)\n",
    "        # we can include softmax in network if we want\n",
    "        return x\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a84e05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name='CartPole-v0'\n",
    "\n",
    "# hyperparameters\n",
    "\n",
    "lr=5e-3\n",
    "epochs=200\n",
    "batch_size=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c61a929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   0 \t loss: 15.844 \t return: 19.385 \t ep_len: 19.385\n",
      "epoch:   1 \t loss: 18.628 \t return: 21.319 \t ep_len: 21.319\n",
      "epoch:   2 \t loss: 17.797 \t return: 21.723 \t ep_len: 21.723\n",
      "epoch:   3 \t loss: 18.224 \t return: 21.146 \t ep_len: 21.146\n",
      "epoch:   4 \t loss: 21.776 \t return: 24.095 \t ep_len: 24.095\n",
      "epoch:   5 \t loss: 18.238 \t return: 21.312 \t ep_len: 21.312\n",
      "epoch:   6 \t loss: 23.565 \t return: 25.425 \t ep_len: 25.425\n",
      "epoch:   7 \t loss: 23.906 \t return: 28.800 \t ep_len: 28.800\n",
      "epoch:   8 \t loss: 20.368 \t return: 24.732 \t ep_len: 24.732\n",
      "epoch:   9 \t loss: 26.749 \t return: 29.647 \t ep_len: 29.647\n",
      "epoch:  10 \t loss: 22.654 \t return: 28.389 \t ep_len: 28.389\n",
      "epoch:  11 \t loss: 28.063 \t return: 31.844 \t ep_len: 31.844\n",
      "epoch:  12 \t loss: 28.426 \t return: 30.441 \t ep_len: 30.441\n",
      "epoch:  13 \t loss: 35.341 \t return: 40.480 \t ep_len: 40.480\n",
      "epoch:  14 \t loss: 28.355 \t return: 33.258 \t ep_len: 33.258\n",
      "epoch:  15 \t loss: 36.083 \t return: 40.360 \t ep_len: 40.360\n",
      "epoch:  16 \t loss: 29.427 \t return: 36.071 \t ep_len: 36.071\n",
      "epoch:  17 \t loss: 24.604 \t return: 31.545 \t ep_len: 31.545\n",
      "epoch:  18 \t loss: 37.157 \t return: 44.043 \t ep_len: 44.043\n",
      "epoch:  19 \t loss: 31.420 \t return: 34.759 \t ep_len: 34.759\n",
      "epoch:  20 \t loss: 36.884 \t return: 41.320 \t ep_len: 41.320\n",
      "epoch:  21 \t loss: 39.221 \t return: 42.417 \t ep_len: 42.417\n",
      "epoch:  22 \t loss: 35.066 \t return: 39.296 \t ep_len: 39.296\n",
      "epoch:  23 \t loss: 47.919 \t return: 59.706 \t ep_len: 59.706\n",
      "epoch:  24 \t loss: 38.638 \t return: 44.478 \t ep_len: 44.478\n",
      "epoch:  25 \t loss: 36.850 \t return: 48.619 \t ep_len: 48.619\n",
      "epoch:  26 \t loss: 34.657 \t return: 42.875 \t ep_len: 42.875\n",
      "epoch:  27 \t loss: 36.867 \t return: 51.286 \t ep_len: 51.286\n",
      "epoch:  28 \t loss: 39.721 \t return: 54.263 \t ep_len: 54.263\n",
      "epoch:  29 \t loss: 41.748 \t return: 56.526 \t ep_len: 56.526\n",
      "epoch:  30 \t loss: 40.251 \t return: 53.050 \t ep_len: 53.050\n",
      "epoch:  31 \t loss: 39.738 \t return: 48.048 \t ep_len: 48.048\n",
      "epoch:  32 \t loss: 36.078 \t return: 48.952 \t ep_len: 48.952\n",
      "epoch:  33 \t loss: 41.861 \t return: 54.211 \t ep_len: 54.211\n",
      "epoch:  34 \t loss: 33.520 \t return: 43.826 \t ep_len: 43.826\n",
      "epoch:  35 \t loss: 31.845 \t return: 44.261 \t ep_len: 44.261\n",
      "epoch:  36 \t loss: 47.689 \t return: 60.059 \t ep_len: 60.059\n",
      "epoch:  37 \t loss: 40.605 \t return: 52.684 \t ep_len: 52.684\n",
      "epoch:  38 \t loss: 45.120 \t return: 59.278 \t ep_len: 59.278\n",
      "epoch:  39 \t loss: 33.732 \t return: 51.150 \t ep_len: 51.150\n",
      "epoch:  40 \t loss: 57.888 \t return: 79.462 \t ep_len: 79.462\n",
      "epoch:  41 \t loss: 60.741 \t return: 72.250 \t ep_len: 72.250\n",
      "epoch:  42 \t loss: 60.017 \t return: 68.733 \t ep_len: 68.733\n",
      "epoch:  43 \t loss: 43.686 \t return: 62.412 \t ep_len: 62.412\n",
      "epoch:  44 \t loss: 36.561 \t return: 54.895 \t ep_len: 54.895\n",
      "epoch:  45 \t loss: 51.266 \t return: 73.867 \t ep_len: 73.867\n",
      "epoch:  46 \t loss: 48.092 \t return: 67.133 \t ep_len: 67.133\n",
      "epoch:  47 \t loss: 43.699 \t return: 61.353 \t ep_len: 61.353\n",
      "epoch:  48 \t loss: 53.131 \t return: 78.231 \t ep_len: 78.231\n",
      "epoch:  49 \t loss: 40.903 \t return: 59.235 \t ep_len: 59.235\n",
      "epoch:  50 \t loss: 44.438 \t return: 62.812 \t ep_len: 62.812\n",
      "epoch:  51 \t loss: 55.653 \t return: 67.733 \t ep_len: 67.733\n",
      "epoch:  52 \t loss: 40.765 \t return: 63.562 \t ep_len: 63.562\n",
      "epoch:  53 \t loss: 61.569 \t return: 87.769 \t ep_len: 87.769\n",
      "epoch:  54 \t loss: 60.517 \t return: 85.143 \t ep_len: 85.143\n",
      "epoch:  55 \t loss: 44.604 \t return: 65.875 \t ep_len: 65.875\n",
      "epoch:  56 \t loss: 55.306 \t return: 73.071 \t ep_len: 73.071\n",
      "epoch:  57 \t loss: 62.504 \t return: 87.417 \t ep_len: 87.417\n",
      "epoch:  58 \t loss: 63.554 \t return: 87.667 \t ep_len: 87.667\n",
      "epoch:  59 \t loss: 52.712 \t return: 76.000 \t ep_len: 76.000\n",
      "epoch:  60 \t loss: 59.296 \t return: 89.250 \t ep_len: 89.250\n",
      "epoch:  61 \t loss: 73.746 \t return: 97.455 \t ep_len: 97.455\n",
      "epoch:  62 \t loss: 70.642 \t return: 95.455 \t ep_len: 95.455\n",
      "epoch:  63 \t loss: 50.383 \t return: 77.643 \t ep_len: 77.643\n",
      "epoch:  64 \t loss: 64.517 \t return: 99.273 \t ep_len: 99.273\n",
      "epoch:  65 \t loss: 57.112 \t return: 89.250 \t ep_len: 89.250\n",
      "epoch:  66 \t loss: 52.837 \t return: 75.643 \t ep_len: 75.643\n",
      "epoch:  67 \t loss: 64.489 \t return: 96.727 \t ep_len: 96.727\n",
      "epoch:  68 \t loss: 53.647 \t return: 80.538 \t ep_len: 80.538\n",
      "epoch:  69 \t loss: 71.187 \t return: 112.222 \t ep_len: 112.222\n",
      "epoch:  70 \t loss: 52.563 \t return: 81.769 \t ep_len: 81.769\n",
      "epoch:  71 \t loss: 69.336 \t return: 103.700 \t ep_len: 103.700\n",
      "epoch:  72 \t loss: 60.747 \t return: 102.100 \t ep_len: 102.100\n",
      "epoch:  73 \t loss: 62.228 \t return: 92.091 \t ep_len: 92.091\n",
      "epoch:  74 \t loss: 79.212 \t return: 131.500 \t ep_len: 131.500\n",
      "epoch:  75 \t loss: 63.241 \t return: 92.182 \t ep_len: 92.182\n",
      "epoch:  76 \t loss: 74.876 \t return: 119.889 \t ep_len: 119.889\n",
      "epoch:  77 \t loss: 85.997 \t return: 137.875 \t ep_len: 137.875\n",
      "epoch:  78 \t loss: 88.784 \t return: 143.000 \t ep_len: 143.000\n",
      "epoch:  79 \t loss: 90.746 \t return: 155.571 \t ep_len: 155.571\n",
      "epoch:  80 \t loss: 85.783 \t return: 140.125 \t ep_len: 140.125\n",
      "epoch:  81 \t loss: 73.490 \t return: 115.444 \t ep_len: 115.444\n",
      "epoch:  82 \t loss: 61.943 \t return: 100.400 \t ep_len: 100.400\n",
      "epoch:  83 \t loss: 81.889 \t return: 128.750 \t ep_len: 128.750\n",
      "epoch:  84 \t loss: 75.330 \t return: 131.250 \t ep_len: 131.250\n",
      "epoch:  85 \t loss: 94.346 \t return: 170.333 \t ep_len: 170.333\n",
      "epoch:  86 \t loss: 79.334 \t return: 145.375 \t ep_len: 145.375\n",
      "epoch:  87 \t loss: 76.048 \t return: 138.500 \t ep_len: 138.500\n",
      "epoch:  88 \t loss: 83.388 \t return: 143.000 \t ep_len: 143.000\n",
      "epoch:  89 \t loss: 78.598 \t return: 129.375 \t ep_len: 129.375\n",
      "epoch:  90 \t loss: 87.234 \t return: 157.286 \t ep_len: 157.286\n",
      "epoch:  91 \t loss: 84.343 \t return: 147.750 \t ep_len: 147.750\n",
      "epoch:  92 \t loss: 85.870 \t return: 155.714 \t ep_len: 155.714\n",
      "epoch:  93 \t loss: 87.623 \t return: 169.667 \t ep_len: 169.667\n",
      "epoch:  94 \t loss: 95.746 \t return: 179.333 \t ep_len: 179.333\n",
      "epoch:  95 \t loss: 94.306 \t return: 182.167 \t ep_len: 182.167\n",
      "epoch:  96 \t loss: 77.803 \t return: 131.250 \t ep_len: 131.250\n",
      "epoch:  97 \t loss: 91.171 \t return: 169.333 \t ep_len: 169.333\n",
      "epoch:  98 \t loss: 85.278 \t return: 160.571 \t ep_len: 160.571\n",
      "epoch:  99 \t loss: 86.414 \t return: 162.857 \t ep_len: 162.857\n",
      "epoch: 100 \t loss: 80.046 \t return: 151.714 \t ep_len: 151.714\n",
      "epoch: 101 \t loss: 77.690 \t return: 142.375 \t ep_len: 142.375\n",
      "epoch: 102 \t loss: 91.342 \t return: 173.500 \t ep_len: 173.500\n",
      "epoch: 103 \t loss: 89.206 \t return: 173.833 \t ep_len: 173.833\n",
      "epoch: 104 \t loss: 78.294 \t return: 150.000 \t ep_len: 150.000\n",
      "epoch: 105 \t loss: 86.273 \t return: 167.500 \t ep_len: 167.500\n",
      "epoch: 106 \t loss: 78.240 \t return: 151.143 \t ep_len: 151.143\n",
      "epoch: 107 \t loss: 86.844 \t return: 165.000 \t ep_len: 165.000\n",
      "epoch: 108 \t loss: 79.573 \t return: 151.000 \t ep_len: 151.000\n",
      "epoch: 109 \t loss: 90.259 \t return: 180.333 \t ep_len: 180.333\n",
      "epoch: 110 \t loss: 79.585 \t return: 152.714 \t ep_len: 152.714\n",
      "epoch: 111 \t loss: 81.835 \t return: 154.857 \t ep_len: 154.857\n",
      "epoch: 112 \t loss: 88.149 \t return: 179.500 \t ep_len: 179.500\n",
      "epoch: 113 \t loss: 84.759 \t return: 165.143 \t ep_len: 165.143\n",
      "epoch: 114 \t loss: 77.602 \t return: 146.000 \t ep_len: 146.000\n",
      "epoch: 115 \t loss: 88.935 \t return: 173.500 \t ep_len: 173.500\n",
      "epoch: 116 \t loss: 88.241 \t return: 173.500 \t ep_len: 173.500\n",
      "epoch: 117 \t loss: 91.478 \t return: 180.667 \t ep_len: 180.667\n",
      "epoch: 118 \t loss: 93.526 \t return: 184.500 \t ep_len: 184.500\n",
      "epoch: 119 \t loss: 87.932 \t return: 171.000 \t ep_len: 171.000\n",
      "epoch: 120 \t loss: 83.826 \t return: 162.000 \t ep_len: 162.000\n",
      "epoch: 121 \t loss: 85.700 \t return: 165.429 \t ep_len: 165.429\n",
      "epoch: 122 \t loss: 98.609 \t return: 193.833 \t ep_len: 193.833\n",
      "epoch: 123 \t loss: 91.155 \t return: 180.833 \t ep_len: 180.833\n",
      "epoch: 124 \t loss: 94.349 \t return: 189.500 \t ep_len: 189.500\n",
      "epoch: 125 \t loss: 82.241 \t return: 158.571 \t ep_len: 158.571\n",
      "epoch: 126 \t loss: 84.970 \t return: 169.000 \t ep_len: 169.000\n",
      "epoch: 127 \t loss: 91.354 \t return: 173.167 \t ep_len: 173.167\n",
      "epoch: 128 \t loss: 87.384 \t return: 169.500 \t ep_len: 169.500\n",
      "epoch: 129 \t loss: 88.580 \t return: 173.833 \t ep_len: 173.833\n",
      "epoch: 130 \t loss: 89.673 \t return: 168.286 \t ep_len: 168.286\n",
      "epoch: 131 \t loss: 76.213 \t return: 149.714 \t ep_len: 149.714\n",
      "epoch: 132 \t loss: 82.238 \t return: 161.143 \t ep_len: 161.143\n",
      "epoch: 133 \t loss: 87.720 \t return: 177.833 \t ep_len: 177.833\n",
      "epoch: 134 \t loss: 95.535 \t return: 182.833 \t ep_len: 182.833\n",
      "epoch: 135 \t loss: 85.933 \t return: 175.167 \t ep_len: 175.167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 136 \t loss: 77.735 \t return: 144.429 \t ep_len: 144.429\n",
      "epoch: 137 \t loss: 95.010 \t return: 191.333 \t ep_len: 191.333\n",
      "epoch: 138 \t loss: 87.069 \t return: 176.667 \t ep_len: 176.667\n",
      "epoch: 139 \t loss: 86.498 \t return: 170.167 \t ep_len: 170.167\n",
      "epoch: 140 \t loss: 95.855 \t return: 194.167 \t ep_len: 194.167\n",
      "epoch: 141 \t loss: 90.016 \t return: 178.500 \t ep_len: 178.500\n",
      "epoch: 142 \t loss: 92.532 \t return: 178.000 \t ep_len: 178.000\n",
      "epoch: 143 \t loss: 93.873 \t return: 193.833 \t ep_len: 193.833\n",
      "epoch: 144 \t loss: 92.849 \t return: 184.167 \t ep_len: 184.167\n",
      "epoch: 145 \t loss: 92.632 \t return: 181.833 \t ep_len: 181.833\n",
      "epoch: 146 \t loss: 90.206 \t return: 185.833 \t ep_len: 185.833\n",
      "epoch: 147 \t loss: 88.692 \t return: 182.833 \t ep_len: 182.833\n",
      "epoch: 148 \t loss: 92.416 \t return: 191.000 \t ep_len: 191.000\n",
      "epoch: 149 \t loss: 93.158 \t return: 191.333 \t ep_len: 191.333\n",
      "epoch: 150 \t loss: 93.843 \t return: 181.167 \t ep_len: 181.167\n",
      "epoch: 151 \t loss: 94.061 \t return: 199.000 \t ep_len: 199.000\n",
      "epoch: 152 \t loss: 89.699 \t return: 177.167 \t ep_len: 177.167\n",
      "epoch: 153 \t loss: 95.761 \t return: 189.500 \t ep_len: 189.500\n",
      "epoch: 154 \t loss: 89.384 \t return: 178.000 \t ep_len: 178.000\n",
      "epoch: 155 \t loss: 97.692 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 156 \t loss: 88.273 \t return: 172.833 \t ep_len: 172.833\n",
      "epoch: 157 \t loss: 89.625 \t return: 184.667 \t ep_len: 184.667\n",
      "epoch: 158 \t loss: 94.113 \t return: 189.000 \t ep_len: 189.000\n",
      "epoch: 159 \t loss: 95.126 \t return: 198.167 \t ep_len: 198.167\n",
      "epoch: 160 \t loss: 94.044 \t return: 191.333 \t ep_len: 191.333\n",
      "epoch: 161 \t loss: 89.357 \t return: 179.333 \t ep_len: 179.333\n",
      "epoch: 162 \t loss: 89.699 \t return: 185.167 \t ep_len: 185.167\n",
      "epoch: 163 \t loss: 95.611 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 164 \t loss: 86.434 \t return: 167.167 \t ep_len: 167.167\n",
      "epoch: 165 \t loss: 94.962 \t return: 188.833 \t ep_len: 188.833\n",
      "epoch: 166 \t loss: 92.531 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 167 \t loss: 94.950 \t return: 191.500 \t ep_len: 191.500\n",
      "epoch: 168 \t loss: 86.097 \t return: 170.000 \t ep_len: 170.000\n",
      "epoch: 169 \t loss: 92.476 \t return: 182.333 \t ep_len: 182.333\n",
      "epoch: 170 \t loss: 78.383 \t return: 148.857 \t ep_len: 148.857\n",
      "epoch: 171 \t loss: 93.580 \t return: 195.000 \t ep_len: 195.000\n",
      "epoch: 172 \t loss: 91.640 \t return: 184.833 \t ep_len: 184.833\n",
      "epoch: 173 \t loss: 95.576 \t return: 198.000 \t ep_len: 198.000\n",
      "epoch: 174 \t loss: 92.576 \t return: 182.667 \t ep_len: 182.667\n",
      "epoch: 175 \t loss: 95.161 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 176 \t loss: 89.055 \t return: 184.500 \t ep_len: 184.500\n",
      "epoch: 177 \t loss: 94.083 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 178 \t loss: 93.549 \t return: 196.000 \t ep_len: 196.000\n",
      "epoch: 179 \t loss: 94.190 \t return: 191.667 \t ep_len: 191.667\n",
      "epoch: 180 \t loss: 87.396 \t return: 184.333 \t ep_len: 184.333\n",
      "epoch: 181 \t loss: 91.073 \t return: 177.833 \t ep_len: 177.833\n",
      "epoch: 182 \t loss: 95.868 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 183 \t loss: 97.704 \t return: 198.833 \t ep_len: 198.833\n",
      "epoch: 184 \t loss: 88.176 \t return: 184.500 \t ep_len: 184.500\n",
      "epoch: 185 \t loss: 89.862 \t return: 185.667 \t ep_len: 185.667\n",
      "epoch: 186 \t loss: 95.868 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 187 \t loss: 92.893 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 188 \t loss: 91.324 \t return: 197.333 \t ep_len: 197.333\n",
      "epoch: 189 \t loss: 95.290 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 190 \t loss: 93.398 \t return: 193.833 \t ep_len: 193.833\n",
      "epoch: 191 \t loss: 95.564 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 192 \t loss: 88.933 \t return: 187.000 \t ep_len: 187.000\n",
      "epoch: 193 \t loss: 89.460 \t return: 189.667 \t ep_len: 189.667\n",
      "epoch: 194 \t loss: 94.945 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 195 \t loss: 94.110 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 196 \t loss: 93.547 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 197 \t loss: 93.210 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 198 \t loss: 95.637 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 199 \t loss: 92.777 \t return: 200.000 \t ep_len: 200.000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# make environment\n",
    "env = gym.make(env_name)\n",
    "\n",
    "# get diensions for policy network\n",
    "obs_dim = env.observation_space.shape[0]\n",
    "n_acts = env.action_space.n\n",
    "\n",
    "# make core of policy network\n",
    "logits_net = policynet(obs_dim, 32, n_acts)\n",
    "\n",
    "# this function gets action distribution\n",
    "def get_policy(obs):\n",
    "    logits = logits_net(obs)\n",
    "    return Categorical(logits=logits)\n",
    "\n",
    "# make action selection function (outputs int actions, sampled from policy)\n",
    "def get_action(obs):\n",
    "    return get_policy(obs).sample().item()\n",
    "\n",
    "# compute loss, for VPG is log prob times advantage (value - reward). Instead we just use \n",
    "#reward, R(tau) since it works well enough\n",
    "def compute_loss(obs, act, weights):\n",
    "    logp = get_policy(obs).log_prob(act)\n",
    "    return -(logp * weights).mean()\n",
    "\n",
    "# adam optimizer\n",
    "optimizer = torch.optim.Adam(logits_net.parameters(), lr=lr)\n",
    "\n",
    "def train_one_epoch():\n",
    "    # make some empty lists for logging.\n",
    "    batch_obs = []          # for observations\n",
    "    batch_acts = []         # for actions\n",
    "    batch_weights = []      # for R(tau) weighting in policy gradient\n",
    "    batch_rets = []         # for measuring episode returns\n",
    "    batch_lens = []         # for measuring episode lengths\n",
    "\n",
    "    # reset episode-specific variables\n",
    "    obs = env.reset()       # first obs comes from starting distribution\n",
    "    done = False            # signal from environment that episode is over\n",
    "    ep_rews = []            # list for rewards accrued throughout ep\n",
    "\n",
    "    # collect experience by acting in the environment with current policy\n",
    "    while True:\n",
    "        # save obs\n",
    "        batch_obs.append(obs.copy())\n",
    "\n",
    "        # act in the environment\n",
    "        act = get_action(torch.as_tensor(obs, dtype=torch.float32))\n",
    "        obs, rew, done, _ = env.step(act)\n",
    "\n",
    "        # save action, reward\n",
    "        batch_acts.append(act)\n",
    "        ep_rews.append(rew)\n",
    "\n",
    "        # check if episode is done, then record some info\n",
    "        if done:\n",
    "            ep_ret, ep_len = sum(ep_rews), len(ep_rews)\n",
    "            batch_rets.append(ep_ret)\n",
    "            batch_lens.append(ep_len)\n",
    "\n",
    "            # the weight for each logprob(a|s) is R(tau)\n",
    "            batch_weights += [ep_ret] * ep_len\n",
    "\n",
    "            # reset episode-specific variables\n",
    "            obs, done, ep_rews = env.reset(), False, []\n",
    "\n",
    "            # end experience loop if we have enough of it\n",
    "            if len(batch_obs) > batch_size:\n",
    "                break\n",
    "    # typical pytorch optimization loop\n",
    "    optimizer.zero_grad()\n",
    "    batch_loss = compute_loss(obs=torch.as_tensor(np.array(batch_obs), dtype=torch.float32),\n",
    "                              act=torch.as_tensor(batch_acts, dtype=torch.int32),\n",
    "                              weights=torch.as_tensor(batch_weights, dtype=torch.float32)\n",
    "                              )\n",
    "    batch_loss.backward()\n",
    "    optimizer.step()\n",
    "    return batch_loss, batch_rets, batch_lens\n",
    "\n",
    "for i in range(epochs):\n",
    "    batch_loss, batch_rets, batch_lens = train_one_epoch()\n",
    "    print('epoch: %3d \\t loss: %.3f \\t return: %.3f \\t ep_len: %.3f'%\n",
    "            (i, batch_loss, np.mean(batch_rets), np.mean(batch_lens)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b4c1a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 200 timesteps\n"
     ]
    }
   ],
   "source": [
    "# test model \n",
    "\n",
    "# use this if you want to save video output, otherwise comment out\n",
    "env = gym.wrappers.Monitor(gym.make('CartPole-v0'), './', force=True)\n",
    "\n",
    "# test our agent\n",
    "for i_episode in range(1):\n",
    "    \n",
    "    observation = env.reset()\n",
    "    for t in range(500):\n",
    "        env.render()\n",
    "        #print(observation)\n",
    "        action = get_action(torch.as_tensor(observation, dtype=torch.float32))\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        if done:\n",
    "            print(\"Episode finished after {} timesteps\".format(t+1))\n",
    "            break\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
